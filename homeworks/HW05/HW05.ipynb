{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mirea-aie-2025/aie-course-meta/refs/heads/main/seminars/S05/S05-hw-dataset.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "print('=' * 52)\n",
    "print(df.info())\n",
    "print('=' * 52)\n",
    "print(df.describe())\n",
    "print('=' * 52)\n",
    "print(df.value_counts(normalize=True))\n",
    "print('=' * 52)\n",
    "X = df.drop('client_id', axis=1)\n",
    "X = X.drop('default', axis=1)\n",
    "y = df.default\n",
    "print(abs(1 -len(df[df.default == 1])/len(df)))\n",
    "# Датасет состоит из 3000 объектов и имеет 17 признаков, и разделён на два класса по таргету 'default' в соотношении 59 на 41\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "bl = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "bl.fit(X_train, y_train)\n",
    "y_proba = bl.predict_proba(X_test)[:, 1]\n",
    "y_pred = bl.predict(X_test)\n",
    "print(\"Accuracy :\", skm.accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC  :\", skm.roc_auc_score(y_test, y_proba))\n",
    "# Бейзлайн классифицировал датасет на две группы по таргету 'default'. Точность такой модели классификации полностью соответствует соотношению классов полученному в предыдущем пункте.\n",
    "# Точность этой модели соответствует нижней планке для моделей классификации. Если точность итоговой модели будет ниже этой (0.59), то это будет означать её абсолютную неэффективность.\n",
    "\n",
    "print('=' * 52)\n",
    "lr = Pipeline(steps=[('skelter', StandardScaler()), (\"logreg\", LogisticRegression(penalty='l2' , C=1.0, solver='liblinear', random_state=42))])\n",
    "lr.fit(X_train, y_train)\n",
    "y_lr_pred = lr.predict(X_test)\n",
    "y_lr_proba = lr.predict_proba(X_test)[:, 1]\n",
    "print(\"Accuracy :\", skm.accuracy_score(y_test, y_lr_pred))\n",
    "print(\"ROC-AUC  :\", skm.roc_auc_score(y_test, y_lr_proba))\n",
    "print('=' * 52)\n",
    "gs = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid={\"logreg__C\": [0.01, 0.1, 1.0, 10.0, 100.0],},\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\", gs.best_params_)\n",
    "print(\"Лучший ROC-AUC (по CV):\", gs.best_score_)\n",
    "print('=' * 52)\n",
    "bm = gs.best_estimator_\n",
    "y_lr_best_pred = bm.predict(X_test)\n",
    "y_lr_best_proba = bm.predict_proba(X_test)[:, 1]\n",
    "print(\"Accuracy :\", skm.accuracy_score(y_test, y_lr_best_pred))\n",
    "print(\"ROC-AUC  :\", skm.roc_auc_score(y_test, y_lr_best_proba))\n",
    "skm.RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_lr_best_proba,\n",
    ")\n",
    "plt.savefig('figures/f1')\n",
    "plt.show()\n",
    "skm.PrecisionRecallDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_lr_best_proba,\n",
    ")\n",
    "plt.savefig('figures/f2')\n",
    "plt.show()\n",
    "# Логическая регрессия показала значительно лучший результат, чем бейзлайн (Accuracy: 0.8 против 0.59 и ROC-AUC: 0.87 против 0.5)\n",
    "# Подобная разница происходит из-за того, что бейзлайн грубо оценивает принадлежность всех объектов к одному классу (как если бы мы записали все объекты в самый многочисленный класс).\n",
    "# В свою очередь линейная регрессия является полноценной моделью классификации, показывающей значительно лучший результат.\n",
    "# Однако подбор лучших параметров регуляризации для C (базово был задан С=1.0, а лучший С=10.0) не дал значительных результатов (отличае лишь в сотых долях процента).\n",
    "# Модель логической регрессии кажется разумной для этой задачи, ибо она показывает довольно высокую точность (0.8) на заданом датасете и ROC-AUC (0.88)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
